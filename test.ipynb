{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caad3160ae04580a30cdeed79daf296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from decode import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems that, with AlphaMonarch model, the phenomenom is not obvious on the displayed cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/Users/fangyuanyu/Implementation/CoT-decoding/decode.py:101: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  k_prob = torch.nn.functional.softmax(logit[0][logit[0].argsort()[-k:]])\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/Users/fangyuanyu/Implementation/CoT-decoding/decode.py:63: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  path_prob = torch.nn.functional.softmax(path_prob)\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', tensor(6.1817e-15)), ('the', tensor(1.3026e-08)), ('final', tensor(1.)), ('outcome', tensor(1.2931e-07)), ('depends', tensor(1.0049e-05)), ('on', tensor(1.0518e-07)), ('the', tensor(1.2783e-07)), ('sequential', tensor(2.0955e-07)), ('flips', tensor(1.2241e-05)), ('and', tensor(1.7349e-06)), ('luck,', tensor(9.2372e-07)), ('not', tensor(0.0024)), ('fixed', tensor(6.7402e-10)), ('in', tensor(4.2862e-09)), ('the', tensor(2.0739e-09)), ('given', tensor(1.5983e-08)), ('scenario.', tensor(1.0193e-07)), ('The', tensor(9.4026e-08)), ('coin', tensor(4.5586e-07)), ('may', tensor(1.0442e-07)), ('land', tensor(3.2894e-06)), ('heads', tensor(9.8464e-09)), ('again,', tensor(7.6625e-07)), ('or', tensor(4.1860e-06)), ('it', tensor(7.6430e-08)), ('may', tensor(8.0238e-07)), ('land', tensor(1.7521e-07)), ('tails', tensor(2.0327e-06)), ('after', tensor(2.7625e-05)), (\"Fletcher's\", tensor(0.0004)), ('or', tensor(0.0052)), (\"Conception's\", tensor(0.2318)), ('flip.', tensor(0.0018)), ('Without', tensor(0.0078)), ('specific', tensor(0.0060)), ('information', tensor(0.0037)), ('about', tensor(1.5131e-05)), ('the', tensor(1.3218e-08)), ('results', tensor(1.2004e-07)), ('of', tensor(1.2695e-07)), ('their', tensor(1.2054e-07)), ('flips,', tensor(4.8013e-05)), ('we', tensor(1.2922e-05)), (\"can't\", tensor(0.0092)), ('say', tensor(1.6402e-05)), ('the', tensor(1.7404e-05)), ('coin', tensor(0.0001)), ('is', tensor(0.0093)), ('still', tensor(2.5895e-06)), ('heads', tensor(2.3859e-05)), ('up.</s>', tensor(0.0002))]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Only', tensor(6.1817e-15)), ('if', tensor(1.3026e-08)), ('luck', tensor(1.)), ('maintained', tensor(3.3580e-06)), ('the', tensor(1.7344e-08)), ('identical', tensor(1.6870e-05)), ('outcome', tensor(3.7768e-06)), ('for', tensor(2.4614e-06)), ('both', tensor(9.9315e-07)), ('the', tensor(6.7521e-07)), ('flips.', tensor(1.0328e-06)), ('In', tensor(1.7283e-06)), ('real', tensor(1.7710e-05)), ('life,', tensor(0.0006)), (\"it's\", tensor(5.7719e-07)), ('random', tensor(9.8471e-07)), ('for', tensor(1.6904e-06)), ('each', tensor(2.0447e-06)), ('flip,', tensor(0.1268)), ('so', tensor(8.4270e-07)), ('probability-wise,', tensor(0.0001)), ('heads', tensor(1.3745e-07)), ('may', tensor(1.4398e-07)), ('or', tensor(0.0002)), ('may', tensor(7.8593e-06)), ('not', tensor(4.1778e-06)), ('persist.', tensor(5.1917e-05)), ('', tensor(0.0068)), ('', tensor(4.7502e-06)), ('In', tensor(0.0788)), ('a', tensor(3.0858e-08)), ('hypothetical', tensor(1.9370e-07)), ('scenario', tensor(6.4870e-08)), ('where', tensor(0.2704)), ('both', tensor(0.1218)), ('flips', tensor(0.0396)), ('result', tensor(1.1187e-06)), ('in', tensor(2.0885e-07)), ('no', tensor(1.9161e-06)), ('change,', tensor(0.0029)), ('then', tensor(1.4666e-05)), ('yes,', tensor(3.8874e-06)), ('the', tensor(9.1999e-06)), ('coin', tensor(3.9921e-07)), ('would', tensor(1.6210e-05)), ('still', tensor(0.0010)), ('be', tensor(2.6052e-05)), ('heads', tensor(0.0001)), ('up.', tensor(2.2505e-05)), ('But', tensor(9.4158e-05)), ('in', tensor(9.8292e-05)), ('reality,', tensor(0.0003)), ('coin', tensor(4.0360e-06)), ('flips', tensor(1.4999e-06)), ('are', tensor(7.7704e-06)), ('random', tensor(1.1538e-07)), ('events,', tensor(0.0503))]\n",
      "--------------------\n",
      "[(',', tensor(6.1817e-15)), ('we', tensor(1.3026e-08)), ('cannot', tensor(1.)), ('say', tensor(3.9762e-06)), ('that', tensor(0.0005)), ('the', tensor(5.7291e-06)), ('coin', tensor(6.8049e-05)), ('is', tensor(2.0250e-07)), ('still', tensor(4.2554e-07)), ('heads', tensor(9.8258e-07)), ('up', tensor(0.0002)), ('without', tensor(1.9411e-06)), ('knowing', tensor(4.5451e-05)), ('the', tensor(7.4597e-06)), ('outcomes', tensor(0.0001)), ('of', tensor(1.4557e-06)), ('the', tensor(1.7647e-07)), ('flips', tensor(4.6453e-06)), ('performed', tensor(7.3210e-05)), ('by', tensor(1.3325e-05)), ('Fletcher', tensor(0.0038)), ('and', tensor(0.0007)), ('Conception.', tensor(0.3152)), ('Each', tensor(0.0073)), ('flip', tensor(0.0002)), ('of', tensor(0.0004)), ('a', tensor(0.0002)), ('fair', tensor(3.8910e-07)), ('coin', tensor(8.3264e-06)), ('is', tensor(3.7310e-07)), ('an', tensor(0.0005)), ('independent', tensor(3.3940e-06)), ('event,', tensor(5.9860e-06)), ('and', tensor(5.4862e-06)), ('the', tensor(3.8724e-05)), ('outcome', tensor(2.6345e-06)), ('of', tensor(1.5221e-06)), ('one', tensor(1.2136e-07)), ('flip', tensor(6.1345e-08)), (\"doesn't\", tensor(3.3323e-06)), ('affect', tensor(9.9485e-07)), ('the', tensor(1.6636e-06)), ('outcome', tensor(0.0032)), ('of', tensor(0.0008)), ('another', tensor(2.8759e-06)), ('flip.', tensor(8.8876e-06)), ('So,', tensor(6.8247e-05)), ('the', tensor(4.9445e-08)), ('heads-up', tensor(2.9065e-07)), ('position', tensor(2.8206e-08)), ('could', tensor(3.0460e-08)), ('have', tensor(3.0498e-08)), ('changed', tensor(0.0003)), ('after', tensor(2.3964e-07)), ('their', tensor(2.5021e-07)), ('flips.', tensor(5.3328e-07)), ('We', tensor(4.8263e-06)), ('need', tensor(7.2659e-06)), ('more', tensor(0.0278)), ('information', tensor(2.2762e-06)), ('to', tensor(2.1784e-08)), ('determine', tensor(1.4142e-06)), ('the', tensor(1.3129e-06)), ('current', tensor(1.6305e-05)), ('side', tensor(6.2683e-06))]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "query=\"Question: A coin is heads up. Fletcher flips the coin. Conception flips the coin. Is the coin still heads up? \\nAnswer: \"\n",
    "k_response = get_k_path_prob(model, tokenizer, query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
