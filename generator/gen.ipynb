{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "import random\n",
    "\n",
    "# Q: So the AgentState will never stop unless the outcome is AgentFinish?\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "   # The input string\n",
    "   input: str\n",
    "   # The list of previous messages in the conversation\n",
    "   chat_history: list[BaseMessage]\n",
    "   # The outcome of a given call to the agent\n",
    "   # Needs `None` as a valid type, since this is what this will start as\n",
    "   agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "   # List of actions and corresponding observations\n",
    "   # Here we annotate this with `operator.add` to indicate that operations to\n",
    "   # this state should be ADDED to the existing values (not overwrite it)\n",
    "   intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "\n",
    "@tool(\"lower_case\", return_direct=True)\n",
    "def to_lower_case(input:str) -> str:\n",
    "  \"\"\"Returns the input as all lower case.\"\"\"\n",
    "  return input.lower()\n",
    "\n",
    "@tool(\"random_number\", return_direct=True)\n",
    "def random_number_maker(input:str) -> str:\n",
    "    \"\"\"Returns a random number between 0-100.\"\"\"\n",
    "    return random.randint(0, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [to_lower_case,random_number_maker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm,\n",
    "                                               tools,\n",
    "                                               prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the capital of France?'),\n",
       " AIMessage(content='The capital of France is Paris.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a chat prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What is the capital of {country}?\"),\n",
    "    (\"ai\", \"The capital of {country} is {capital}.\")\n",
    "])\n",
    "\n",
    "# Invoke the template with input values\n",
    "chat_prompt = chat_template.invoke({\"country\": \"France\", \"capital\": \"Paris\"})\n",
    "# chat_prompt = chat_template.format_messages(conutry=\"France\", capital=\"Paris\")\n",
    "\n",
    "# Get the formatted chat messages\n",
    "formatted_messages = chat_prompt.to_messages()\n",
    "\n",
    "# Print the formatted messages\n",
    "formatted_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(mul_two)\n",
    "sequence = runnable_1 | runnable_2\n",
    "# Or equivalently:\n",
    "# sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
    "sequence.invoke(1)\n",
    "await sequence.ainvoke(1)\n",
    "\n",
    "# sequence.batch([1, 2, 3])\n",
    "# await sequence.abatch([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(add_one)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_runnable.invoke gets you reponse from the agent\n",
    "# tool_executor.invoke gets you output from the tools called\n",
    "# Define the agent/graph\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent_runnable.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def execute_tools(data):\n",
    "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
    "    agent_action = data['agent_outcome']\n",
    "    # Execute the tool\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    print(f\"The agent action is {agent_action}\")\n",
    "    print(f\"The tool result is: {output}\")\n",
    "    # Return the output\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "# Define logic that will be used to determine which conditional edge to go down\n",
    "def should_continue(data):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(data['agent_outcome'], AgentFinish):\n",
    "        return \"end\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'agent': [Branch(condition=<function should_continue at 0x129ce5940>, ends={'continue': 'action', 'end': '__end__'})]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent': RunnableLambda(run_agent), 'action': RunnableLambda(execute_tools)},\n",
       " {('action', 'agent')})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.nodes, workflow.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': <langgraph.channels.last_value.LastValue at 0x12893c410>,\n",
       " 'chat_history': <langgraph.channels.last_value.LastValue at 0x129aa6c10>,\n",
       " 'agent_outcome': <langgraph.channels.last_value.LastValue at 0x129aa6690>,\n",
       " 'intermediate_steps': <langgraph.channels.binop.BinaryOperatorAggregate at 0x129aa6b50>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='random_number', tool_input={'input': 'random number'}, log=\"\\nInvoking: `random_number` with `{'input': 'random number'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call'})])}\n",
      "----\n",
      "The agent action is tool='random_number' tool_input={'input': 'random number'} log=\"\\nInvoking: `random_number` with `{'input': 'random number'}`\\n\\n\\n\" message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call'})]\n",
      "The tool result is: 35\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='random_number', tool_input={'input': 'random number'}, log=\"\\nInvoking: `random_number` with `{'input': 'random number'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call'})]), '35')]}\n",
      "----\n",
      "{'agent_outcome': AgentActionMessageLog(tool='lower_case', tool_input={'input': 'THIRTY-FIVE'}, log=\"\\nInvoking: `lower_case` with `{'input': 'THIRTY-FIVE'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"THIRTY-FIVE\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call'})])}\n",
      "----\n",
      "The agent action is tool='lower_case' tool_input={'input': 'THIRTY-FIVE'} log=\"\\nInvoking: `lower_case` with `{'input': 'THIRTY-FIVE'}`\\n\\n\\n\" message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"THIRTY-FIVE\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call'})]\n",
      "The tool result is: thirty-five\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='lower_case', tool_input={'input': 'THIRTY-FIVE'}, log=\"\\nInvoking: `lower_case` with `{'input': 'THIRTY-FIVE'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"THIRTY-FIVE\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call'})]), 'thirty-five')]}\n",
      "----\n",
      "{'agent_outcome': AgentFinish(return_values={'output': 'The random number is 35. In words, it is \"thirty-five\" in lower case.'}, log='The random number is 35. In words, it is \"thirty-five\" in lower case.')}\n",
      "----\n",
      "{'input': 'give me a random number and then write in words and make it lower case.', 'chat_history': [], 'agent_outcome': AgentFinish(return_values={'output': 'The random number is 35. In words, it is \"thirty-five\" in lower case.'}, log='The random number is 35. In words, it is \"thirty-five\" in lower case.'), 'intermediate_steps': [(AgentActionMessageLog(tool='random_number', tool_input={'input': 'random number'}, log=\"\\nInvoking: `random_number` with `{'input': 'random number'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"random number\"}', 'name': 'random_number'}}, response_metadata={'finish_reason': 'function_call'})]), '35'), (AgentActionMessageLog(tool='lower_case', tool_input={'input': 'THIRTY-FIVE'}, log=\"\\nInvoking: `lower_case` with `{'input': 'THIRTY-FIVE'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"input\":\"THIRTY-FIVE\"}', 'name': 'lower_case'}}, response_metadata={'finish_reason': 'function_call'})]), 'thirty-five')]}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"give me a random number and then write in words and make it lower case.\", \"chat_history\": []}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
